{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project (MAT381E-Fall-2022)\n",
    "\n",
    "**Subject**: Sentiment & Data Analysis of Book Reviews\n",
    "\n",
    "**Student**: Ecemnur Erman - 090180317 - erman18@itu.edu.tr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "* I am going to use a dataset from Kaggle which contains 3 million Goodreads user reviews for 212404 unique books ([Kaggle Dataset](https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "* The rating that a person gives to a book is sentimentally correlated to what they think of the book--hence their review. Ratings are just numbers (on a scale from a numeric to a numeric, to give the book a 'value' so that it could be compared to either another book or how it's perceieved to others averagely) and reviews are just a bunch of words. Or are they? That's what I aspire to find out. \n",
    "* People tend to base their ratings on how they feel about the book, whether they liked it or not, or whether they would recommend it to an another person or not. So in order to measure the accuracy of 'average rating', we should be able to utilize those 'bunch of words' and make sense of them--but mathematically. \n",
    "* Like I just explained, reviews and ratings are correlated. So in a world, where we could 'compare' them per se, their same-scaled values should be approximately the same. My project aims to prove this hypothesis. \n",
    "* Sentiment Analysis and Natural Language Processing (NLP) are going to be the machine learning methods I will be using. There are libraries in Python which I can utilize (nltk & nltk.sentiment).\n",
    "* These libraries contain a lot of words in different languages. Based on the emotion theory in psychology, three types of values are assigned to these words: Positive, Neutral, Negative.\n",
    "* My dataset's language is English, so I will use 'English'.\n",
    "* My process starts with constructing a list of all the books that were reviewed in this dataset, sort them out based on the average rating they got and show the TOP 100 Books visually (since the dataset is very large and showing all of them visually would be time consuming). \n",
    "* And then, I am going to analyze the texts of TOP 100 Books reviews to find out whether they are positive, negative or neutral, by assigning them positive/neutral/negative scores and calculate the average positivity score of each book. \n",
    "* After visualizing TOP 100 Books and their positivity scores, I am going to compare the two results to see if the average ratings and the sentimentality of the reviews match.\n"
    "* It is presumable that my hypothesis could backfire because of the lack of of the data (NaN values in Book Rating Column etc.), the question that whether the emotion theory really resonates with the assignment of the values to the words or the under-development of NLP techniques in terms of assigning certain values to words.\n",
    "* However, NLP & Sentiment Analysis are widely used methods to predict how the text 'sounds' in terms of emotions so I believe that I will get an approximately close result to the actual. 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atabey's Notes\n",
    "\n",
    "## Round 1\n",
    "\n",
    "I like the dataset. However, your questions are rather thin. It looks like you can write the required code in less than an hour to answer these questions.\n",
    "\n",
    "Here are the things you must provide:\n",
    "\n",
    "1. Provide a sample of the data and explain the pieces.\n",
    "2. State your hypotheses (there is a correlation between the sentiment scores of the reviews and numerical scores) and the questions you are asking.\n",
    "3. Which machine learning methods, techniques and algorithms are available that would help you to answer the questions and confirm your hypothesis.\n",
    "4. How are you going to test if and how well your techniques worked? \n",
    "5. How are you going to know if your techniques confirm or contradict your hypothesis?\n",
    "\n",
    "## Round 2\n",
    "\n",
    "You haven't made any of the changes I asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
